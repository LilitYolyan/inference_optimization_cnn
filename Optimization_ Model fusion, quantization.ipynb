{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54975c6",
   "metadata": {},
   "source": [
    "# Inference Optimization for Convolutional Netwroks\n",
    "### Model fusion, quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64754000",
   "metadata": {},
   "source": [
    "### TODO: Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a21dd26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, quantization\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import os\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b5ed4",
   "metadata": {},
   "source": [
    "### To try\n",
    "- Create model, fuse and quantizaiton, test on speed and size\n",
    "- Explanation and test of accuracy on resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235c9f7",
   "metadata": {},
   "source": [
    "### Create model, fuse and quantizaiton, test on speed and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb803a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20,kernel_size=(5, 5))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # initialize second set of CONV => RELU => POOL layers\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = nn.Linear(in_features=50*53*53, out_features=500)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONV => RELU => POOL layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # pass the output from the previous layer through the second set of CONV => RELU => POOL layers\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # flatten the output from the previous layer and pass it through our only set of FC => RELU layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        # pass the output to our softmax classifier to get our output predictions\n",
    "        x = self.fc2(x)\n",
    "        output = self.Softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "349c48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes in network\n",
    "\n",
    "class NetQuant(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetQuant, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20,kernel_size=(5, 5))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # initialize second set of CONV => RELU => POOL layers\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = nn.Linear(in_features=50*53*53, out_features=500)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.contiguous(memory_format=torch.channels_last)\n",
    "        x = self.quant(x)\n",
    "        # pass the input through our first set of CONV => RELU => POOL layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # pass the output from the previous layer through the second set of CONV => RELU => POOL layers\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # flatten the output from the previous layer and pass it through our only set of FC => RELU layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        # pass the output to our softmax classifier to get our output predictions\n",
    "        x = self.fc2(x)\n",
    "        x = self.dequant(x)\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5c1f4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetQuant(\n",
       "  (quant): QuantStub()\n",
       "  (conv1): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=140450, out_features=500, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (dequant): DeQuantStub()\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.eval()\n",
    "net_quant = NetQuant()\n",
    "net_quant.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69735cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_quant.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "torch.backends.quantized.engine = \"fbgemm\"\n",
    "net_quant = torch.quantization.prepare(net_quant.cpu(), inplace=False)\n",
    "net_quant = torch.quantization.convert(net_quant, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c2e55",
   "metadata": {},
   "source": [
    "### Check size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e534d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 20, 220, 220]           1,520\n",
      "              ReLU-2         [-1, 20, 220, 220]               0\n",
      "         MaxPool2d-3         [-1, 20, 110, 110]               0\n",
      "            Conv2d-4         [-1, 50, 106, 106]          25,050\n",
      "              ReLU-5         [-1, 50, 106, 106]               0\n",
      "         MaxPool2d-6           [-1, 50, 53, 53]               0\n",
      "            Linear-7                  [-1, 500]      70,225,500\n",
      "              ReLU-8                  [-1, 500]               0\n",
      "            Linear-9                   [-1, 10]           5,010\n",
      "          Softmax-10                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 70,257,080\n",
      "Trainable params: 70,257,080\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 26.27\n",
      "Params size (MB): 268.01\n",
      "Estimated Total Size (MB): 294.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.cuda(), (3, 224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3483b7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1          [-1, 3, 224, 224]               0\n",
      "            Conv2d-2         [-1, 20, 220, 220]           1,520\n",
      "              ReLU-3         [-1, 20, 220, 220]               0\n",
      "         MaxPool2d-4         [-1, 20, 110, 110]               0\n",
      "            Conv2d-5         [-1, 50, 106, 106]          25,050\n",
      "              ReLU-6         [-1, 50, 106, 106]               0\n",
      "         MaxPool2d-7           [-1, 50, 53, 53]               0\n",
      "            Linear-8                  [-1, 500]      70,225,500\n",
      "              ReLU-9                  [-1, 500]               0\n",
      "           Linear-10                   [-1, 10]           5,010\n",
      "          Softmax-11                   [-1, 10]               0\n",
      "      DeQuantStub-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 70,257,080\n",
      "Trainable params: 70,257,080\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 27.42\n",
      "Params size (MB): 268.01\n",
      "Estimated Total Size (MB): 296.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net_quant.cuda(), (3, 224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ba399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281.03 MB\n"
     ]
    }
   ],
   "source": [
    "# Check model size\n",
    "\n",
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')\n",
    "\n",
    "print_model_size(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19d80a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.28 MB\n"
     ]
    }
   ],
   "source": [
    "print_model_size(net_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e84ba75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.999857671505835"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "281.03/70.26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce6cb3",
   "metadata": {},
   "source": [
    "## Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddfac468",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpp = torch.rand(32, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c73a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized INT8\n",
      "85.3 ms ± 2.09 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantized INT8\")\n",
    "%timeit net_quant(inpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bc8000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating point FP32\n",
      "151 ms ± 4.67 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# compare the performance\n",
    "print(\"Floating point FP32\")\n",
    "%timeit net(inpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31cd19b",
   "metadata": {},
   "source": [
    "### Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8818c97",
   "metadata": {},
   "source": [
    "Finally, to get the most performance out of static quantization, you need to also use module fusion. Module fusion is the technique of combining (\"fusing\") sequences of high-level layers, e.g. Conv2d + Batchnorm, into a single combined layer. This improves performance by pushing the combined sequence of operations into the low-level library, allowing it to be computed in one shot, e.g. without having to surface an intermediate representation back to the PyTorch Python process. This speeds things up and leads to more accurate results, albeit at the cost of debuggability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0648f111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetQuant(\n",
       "  (quant): QuantStub()\n",
       "  (conv1): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=140450, out_features=500, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (dequant): DeQuantStub()\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.eval()\n",
    "net_quant = NetQuant()\n",
    "net_quant.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f74c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "moduls_to_fuse =  [['conv1', 'relu1'], \n",
    "                   ['conv2', 'relu2'], \n",
    "                   ['fc1', 'relu3']]\n",
    "\n",
    "net_quant_fused = torch.quantization.fuse_modules(net_quant, moduls_to_fuse)\n",
    "\n",
    "net_fused = torch.quantization.fuse_modules(net, moduls_to_fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acc0d212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lilityolyan/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/ao/quantization/observer.py:177: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/home/lilityolyan/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1124: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "net_quant_fused.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "torch.backends.quantized.engine = \"fbgemm\"\n",
    "net_quant_fused = torch.quantization.prepare(net_quant_fused.cpu(), inplace=False)\n",
    "net_quant_fused = torch.quantization.convert(net_quant_fused, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bddf6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused and quantized model latency\n",
      "81 ms ± 1.49 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fused and quantized model latency\")\n",
    "%timeit net_quant_fused(inpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be7b6d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused model latency\n",
      "146 ms ± 3.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fused model latency\")\n",
    "%timeit net_fused(inpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264a511",
   "metadata": {},
   "source": [
    "yeah it is not supported on CUDA, quantized::linear_dynamic is only supported in CPU. We do not have immediate plans to support CUDA but we plan to publish a doc for custom backends which will make the extension easier.\n",
    "\n",
    "https://pytorch.org/blog/introduction-to-quantization-on-pytorch/\n",
    "\n",
    "### only static is supported\n",
    "\n",
    "diff between dinamic and static?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01784f4c",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "038544f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50 = resnet50(pretrained=True)\n",
    "model_resnet50_quant = quantization.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73fd0ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499072it [00:19, 8590075.64it/s]                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to .\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10('.', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1341c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16a38d78",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:180\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "for i in data_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260dd3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
