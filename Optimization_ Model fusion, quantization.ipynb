{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54975c6",
   "metadata": {},
   "source": [
    "# Inference Optimization for Convolutional Netwroks\n",
    "### Part 1: Model fusion, quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21dd26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lilityolyan/anaconda3/envs/tagger/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import packages \n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b5ed4",
   "metadata": {},
   "source": [
    "### Notebook overview \n",
    "- Create CNN model and the quantized version of the same model\n",
    "- Compare difference in size and latency of two models\n",
    "- Fuse several blocks into one\n",
    "- Compare fused and quantized version with only fused version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235c9f7",
   "metadata": {},
   "source": [
    "### Create simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb803a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20,kernel_size=(5, 5))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Convolutional  Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Fully connected 1\n",
    "        self.fc1 = nn.Linear(in_features=50*53*53, out_features=500)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Fully connected 2\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass the input through block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # pass the input through block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # flatten the output from the previous layer and pass it through fully connected 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        # pass the input through fully connected 2 and Softmax \n",
    "        x = self.fc2(x)\n",
    "        output = self.Softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32dd9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes in network\n",
    "\n",
    "class NetQuant(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetQuant, self).__init__()\n",
    "        # Prepare for quanitzation\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20,kernel_size=(5, 5))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Fully connected 1\n",
    "        self.fc1 = nn.Linear(in_features=50*53*53, out_features=500)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Fully connected 2\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        \n",
    "        # Prepare for dequantization\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.quant(x)\n",
    "        \n",
    "        # pass the input through block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # pass the input through block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # flatten the output from the previous layer and pass it through fully connected 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        # pass the input through fully connected 2 and Softmax \n",
    "        x = self.fc2(x)\n",
    "        x = self.dequant(x)\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c1f4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetQuant(\n",
       "  (quant): QuantStub()\n",
       "  (conv1): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=140450, out_features=500, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (Softmax): Softmax(dim=1)\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define original and quantized models and prepae for evaluation \n",
    "\n",
    "net = Net()\n",
    "net.eval()\n",
    "net_quant = NetQuant()\n",
    "net_quant.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ca95c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lilityolyan/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/ao/quantization/observer.py:177: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/home/lilityolyan/anaconda3/envs/tagger/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1124: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare model quantization and convert to quantized version\n",
    "net_quant.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "torch.backends.quantized.engine = \"fbgemm\"\n",
    "net_quant = torch.quantization.prepare(net_quant.cpu(), inplace=False)\n",
    "net_quant = torch.quantization.convert(net_quant, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c2e55",
   "metadata": {},
   "source": [
    "### Check size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c423f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size whitout quantization: 281 MB \n",
      " Size whit quantization: 70 MB\n",
      "Size ratio: 4.01\n"
     ]
    }
   ],
   "source": [
    "# Check model size\n",
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    size = round(os.path.getsize(\"tmp.pt\")/1e6)\n",
    "    os.remove('tmp.pt')\n",
    "    return size\n",
    "\n",
    "net_size = print_model_size(net)\n",
    "quant_size = print_model_size(net_quant)\n",
    "\n",
    "print(f'Size whitout quantization: {net_size} MB \\n Size whit quantization: {quant_size} MB')\n",
    "print(f'Size ratio: {round(net_size/quant_size, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce6cb3",
   "metadata": {},
   "source": [
    "## Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c73a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating point FP32\n",
      "162 ms ± 6.03 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Quantized INT8\n",
      "94.8 ms ± 15.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# input for the model\n",
    "inpp = torch.rand(32, 3, 224, 224)\n",
    "# compare the performance\n",
    "print(\"Floating point FP32\")\n",
    "%timeit net(inpp)\n",
    "\n",
    "print(\"Quantized INT8\")\n",
    "%timeit net_quant(inpp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61176f0",
   "metadata": {},
   "source": [
    "### Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bdd7325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetQuant(\n",
       "  (quant): QuantStub()\n",
       "  (conv1): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=140450, out_features=500, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (Softmax): Softmax(dim=1)\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define original and quantized models and prepae for evaluation \n",
    "\n",
    "net = Net()\n",
    "net.eval()\n",
    "net_quant = NetQuant()\n",
    "net_quant.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac0e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perpare blocks for the fusion \n",
    "\n",
    "moduls_to_fuse =  [['conv1', 'relu1'], \n",
    "                   ['conv2', 'relu2'], \n",
    "                   ['fc1', 'relu3']]\n",
    "\n",
    "net_quant_fused = torch.quantization.fuse_modules(net_quant, moduls_to_fuse)\n",
    "\n",
    "net_fused = torch.quantization.fuse_modules(net, moduls_to_fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c1672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and quantize the model\n",
    "\n",
    "net_quant_fused.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "torch.backends.quantized.engine = \"fbgemm\"\n",
    "net_quant_fused = torch.quantization.prepare(net_quant_fused.cpu(), inplace=False)\n",
    "net_quant_fused = torch.quantization.convert(net_quant_fused, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "521f4da1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused and quantized model latency\n",
      "91.7 ms ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Fused model latency\n",
      "178 ms ± 9.98 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fused and quantized model latency\")\n",
    "%timeit net_quant_fused(inpp)\n",
    "\n",
    "print(\"Fused model latency\")\n",
    "%timeit net_fused(inpp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
